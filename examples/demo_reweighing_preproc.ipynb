{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f294200",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import time\n",
    "import numpy as np\n",
    "time.sleep(20)\n",
    "from tqdm import tqdm\n",
    "time.sleep(20)\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "time.sleep(20)\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "time.sleep(20)\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "time.sleep(20)\n",
    "from aif360.metrics import ClassificationMetric\n",
    "time.sleep(20)\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "time.sleep(20)\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "        import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "time.sleep(20)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "time.sleep(20)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "time.sleep(20)\n",
    "from sklearn.metrics import accuracy_score\n",
    "time.sleep(20)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "time.sleep(20)\n",
    "import matplotlib.pyplot as plt\n",
    "time.sleep(20)\n",
    "\n",
    "from common_utils import compute_metrics\n",
    "time.sleep(20)\n",
    "\n",
    "## import dataset\n",
    "dataset_used = \"adult\" # \"adult\", \"german\", \"compas\"\n",
    "protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "\n",
    "if dataset_used == \"adult\":\n",
    "#     dataset_orig = AdultDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_adult(['race'])\n",
    "    \n",
    "elif dataset_used == \"german\":\n",
    "#     dataset_orig = GermanDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'age': 1}]\n",
    "        unprivileged_groups = [{'age': 0}]\n",
    "        dataset_orig = load_preproc_data_german(['age'])\n",
    "    \n",
    "elif dataset_used == \"compas\":\n",
    "#     dataset_orig = CompasDataset()\n",
    "    if protected_attribute_used == 1:\n",
    "        privileged_groups = [{'sex': 1}]\n",
    "        unprivileged_groups = [{'sex': 0}]\n",
    "        dataset_orig = load_preproc_data_compas(['sex'])\n",
    "    else:\n",
    "        privileged_groups = [{'race': 1}]\n",
    "        unprivileged_groups = [{'race': 0}]\n",
    "        dataset_orig = load_preproc_data_compas(['race'])\n",
    "\n",
    "all_metrics =  [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "\n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# Get the dataset and split into train and test\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)\n",
    "\n",
    "\n",
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_orig_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, \n",
    "      dataset_orig_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names)\n",
    "\n",
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(dataset_orig_train)\n",
    "dataset_transf_train = RW.transform(dataset_orig_train)\n",
    "\n",
    "### Testing \n",
    "assert np.abs(dataset_transf_train.instance_weights.sum()-dataset_orig_train.instance_weights.sum())<1e-6\n",
    "\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n",
    "\n",
    "### Testing \n",
    "assert np.abs(metric_transf_train.mean_difference()) < 1e-6\n",
    "\n",
    "# Logistic regression classifier and predictions\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "w_train = dataset_orig_train.instance_weights.ravel()\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, \n",
    "         sample_weight=dataset_orig_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "dataset_orig_train_pred = dataset_orig_train.copy()\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "y_valid = dataset_orig_valid_pred.labels\n",
    "dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "y_test = dataset_orig_test_pred.labels\n",
    "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
    "    dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "    dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "    \n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                             dataset_orig_valid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "print(\"Best balanced accuracy (no reweighing) = %.4f\" % np.max(ba_arr))\n",
    "print(\"Optimal classification threshold (no reweighing) = %.4f\" % best_class_thresh)\n",
    "\n",
    "display(Markdown(\"#### Predictions from original testing data\"))\n",
    "bal_acc_arr_orig = []\n",
    "disp_imp_arr_orig = []\n",
    "avg_odds_diff_arr_orig = []\n",
    "\n",
    "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
    "for thresh in tqdm(class_thresh_arr):\n",
    "    \n",
    "    if thresh == best_class_thresh:\n",
    "        disp = True\n",
    "    else:\n",
    "        disp = False\n",
    "    \n",
    "    fav_inds = dataset_orig_test_pred.scores > thresh\n",
    "    dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "    dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "    \n",
    "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = disp)\n",
    "\n",
    "    bal_acc_arr_orig.append(metric_test_bef[\"Balanced accuracy\"])\n",
    "    avg_odds_diff_arr_orig.append(metric_test_bef[\"Average odds difference\"])\n",
    "    disp_imp_arr_orig.append(metric_test_bef[\"Disparate impact\"])\n",
    "    \n",
    "fig, ax1 = plt.subplots(figsize=(10,7))\n",
    "ax1.plot(class_thresh_arr, bal_acc_arr_orig)\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(class_thresh_arr, np.abs(1.0-np.array(disp_imp_arr_orig)), color='r')\n",
    "ax2.set_ylabel('abs(1-disparate impact)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.axvline(best_class_thresh, color='k', linestyle=':')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,7))\n",
    "ax1.plot(class_thresh_arr, bal_acc_arr_orig)\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(class_thresh_arr, avg_odds_diff_arr_orig, color='r')\n",
    "ax2.set_ylabel('avg. odds diff.', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.axvline(best_class_thresh, color='k', linestyle=':')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "\n",
    "scale_transf = StandardScaler()\n",
    "X_train = scale_transf.fit_transform(dataset_transf_train.features)\n",
    "y_train = dataset_transf_train.labels.ravel()\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train,\n",
    "        sample_weight=dataset_transf_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "dataset_transf_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_transf.fit_transform(dataset_transf_test_pred.features)\n",
    "y_test = dataset_transf_test_pred.labels\n",
    "dataset_transf_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "display(Markdown(\"#### Predictions from transformed testing data\"))\n",
    "bal_acc_arr_transf = []\n",
    "disp_imp_arr_transf = []\n",
    "avg_odds_diff_arr_transf = []\n",
    "\n",
    "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
    "for thresh in tqdm(class_thresh_arr):\n",
    "    \n",
    "    if thresh == best_class_thresh:\n",
    "        disp = True\n",
    "    else:\n",
    "        disp = False\n",
    "    \n",
    "    fav_inds = dataset_transf_test_pred.scores > thresh\n",
    "    dataset_transf_test_pred.labels[fav_inds] = dataset_transf_test_pred.favorable_label\n",
    "    dataset_transf_test_pred.labels[~fav_inds] = dataset_transf_test_pred.unfavorable_label\n",
    "    \n",
    "    metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = disp)\n",
    "\n",
    "    bal_acc_arr_transf.append(metric_test_aft[\"Balanced accuracy\"])\n",
    "    avg_odds_diff_arr_transf.append(metric_test_aft[\"Average odds difference\"])\n",
    "    disp_imp_arr_transf.append(metric_test_aft[\"Disparate impact\"])\n",
    "    \n",
    "fig, ax1 = plt.subplots(figsize=(10,7))\n",
    "ax1.plot(class_thresh_arr, bal_acc_arr_transf)\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(class_thresh_arr, np.abs(1.0-np.array(disp_imp_arr_transf)), color='r')\n",
    "ax2.set_ylabel('abs(1-disparate impact)', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.axvline(best_class_thresh, color='k', linestyle=':')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,7))\n",
    "ax1.plot(class_thresh_arr, bal_acc_arr_transf)\n",
    "ax1.set_xlabel('Classification Thresholds', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Balanced Accuracy', color='b', fontsize=16, fontweight='bold')\n",
    "ax1.xaxis.set_tick_params(labelsize=14)\n",
    "ax1.yaxis.set_tick_params(labelsize=14)\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(class_thresh_arr, avg_odds_diff_arr_transf, color='r')\n",
    "ax2.set_ylabel('avg. odds diff.', color='r', fontsize=16, fontweight='bold')\n",
    "ax2.axvline(best_class_thresh, color='k', linestyle=':')\n",
    "ax2.yaxis.set_tick_params(labelsize=14)\n",
    "ax2.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
