{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f294200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "time.sleep(20)\n",
    "import numpy as np\n",
    "time.sleep(20)\n",
    "from pprint import pprint\n",
    "time.sleep(20)\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
    "from aif360.detectors.mdss.ScoringFunctions import Bernoulli\n",
    "from aif360.detectors.mdss.MDSS import MDSS\n",
    "from aif360.detectors.mdss.generator import get_random_subset\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "ad_conversion_dataset = pd.read_csv('ad_campaign_data.csv')\n",
    "ad_conversion_dataset.head()\n",
    "\n",
    "print(f\"Number of (instances, attributes) in the dataset = {ad_conversion_dataset.shape}\")\n",
    "\n",
    "print(f\"Statistics of true conversions (0=no, 1=yes)\")\n",
    "print(ad_conversion_dataset.true_conversion.value_counts())\n",
    "\n",
    "print(f\"Statistics of predicted conversions (0=no, 1=yes)\")\n",
    "print(ad_conversion_dataset.predicted_conversion.value_counts())\n",
    "\n",
    "features_4_scanning = ['college_educated','parents','homeowner','gender','age','income','area','politics','religion']\n",
    "\n",
    "def print_report(data, subset):\n",
    "    \"\"\" Utility function to pretty-print the subsets.\"\"\"\n",
    "    if subset:\n",
    "        to_choose = ad_conversion_dataset[subset.keys()].isin(subset).all(axis = 1)\n",
    "        df = ad_conversion_dataset[['true_conversion', 'predicted_conversion']][to_choose]\n",
    "    else:\n",
    "        for col in features_4_scanning:\n",
    "            subset[col] = list(ad_conversion_dataset[col].unique())\n",
    "        df = ad_conversion_dataset[['true_conversion', 'predicted_conversion']]\n",
    "\n",
    "    true = df['true_conversion'].sum()\n",
    "    pred = df['predicted_conversion'].sum()\n",
    "    \n",
    "    print('\\033[1mSubset: \\033[0m')\n",
    "    pprint(subset)\n",
    "    print('\\033[1mSubset Size: \\033[0m', len(df))\n",
    "    print('\\033[1mTrue Clicks: \\033[0m', true)\n",
    "    print('\\033[1mPredicted Clicks: \\033[0m', pred)\n",
    "    print()\n",
    "    \n",
    "np.random.seed(11)\n",
    "random_subset = get_random_subset(ad_conversion_dataset[features_4_scanning], prob = 0.05, min_elements = 10000)\n",
    "print_report(ad_conversion_dataset, random_subset)\n",
    "\n",
    "# Bias scan\n",
    "scoring_function = Bernoulli(direction='negative')\n",
    "scanner = MDSS(scoring_function)\n",
    " \n",
    "scanned_subset, _ = scanner.scan(ad_conversion_dataset[features_4_scanning], \n",
    "                        expectations = ad_conversion_dataset['predicted_conversion'],\n",
    "                        outcomes = ad_conversion_dataset['true_conversion'], \n",
    "                        penalty = 1, \n",
    "                        num_iters = 1,\n",
    "                        verbose = False)\n",
    "\n",
    "print_report(ad_conversion_dataset, scanned_subset)\n",
    "\n",
    "print_report(ad_conversion_dataset, {'homeowner':[0]})\n",
    "\n",
    "print_report(ad_conversion_dataset, {'homeowner':[1]})\n",
    "\n",
    "def convert_to_standard_dataset(df, target_label_name, scores_name=\"\"):\n",
    "\n",
    "    # List of names corresponding to protected attribute columns in the dataset.\n",
    "    # Note that the terminology \"protected attribute\" used in AI Fairness 360 to\n",
    "    # divide the dataset into multiple groups for measuring and mitigating \n",
    "    # group-level bias.\n",
    "    protected_attributes=['homeowner']\n",
    "    \n",
    "    # columns from the dataset that we want to select for this Bias study\n",
    "    selected_features = ['gender', 'age', 'income', 'area', 'college_educated', 'homeowner', \n",
    "                         'parents', 'predicted_probability']\n",
    "    \n",
    "    # This privileged class is selected based on MDSS subgroup evaluation.\n",
    "    # in previous steps. In our case non-homeowner (homeowner=0) are considered to \n",
    "    # be privileged and homeowners (homeowner=1) are considered as unprivileged.\n",
    "    privileged_classes = [[0]]   \n",
    "\n",
    "    # Label values which are considered favorable are listed. All others are \n",
    "    # unfavorable. Label values are mapped to 1 (favorable) and 0 (unfavorable) \n",
    "    # if they are not already binary and numerical.\n",
    "    favorable_target_label = [1]\n",
    "\n",
    "    # List of column names in the DataFrame which are to be expanded into one-hot vectors.\n",
    "    categorical_features = ['parents','gender','college_educated','area','income', 'age']\n",
    "\n",
    "    # create the `StandardDataset` object\n",
    "    standard_dataset = StandardDataset(df=df, label_name=target_label_name,\n",
    "                                    favorable_classes=favorable_target_label,\n",
    "                                    scores_name=scores_name,\n",
    "                                    protected_attribute_names=protected_attributes,\n",
    "                                    privileged_classes=privileged_classes,\n",
    "                                    categorical_features=categorical_features,\n",
    "                                    features_to_keep=selected_features)\n",
    "    if scores_name==\"\":\n",
    "        standard_dataset.scores = standard_dataset.labels.copy()\n",
    "        \n",
    "    return standard_dataset\n",
    "\n",
    "# Create two StandardDataset objects - one with true conversions and one with\n",
    "# predicted conversions.\n",
    "\n",
    "# First create the predicted dataset\n",
    "ad_standard_dataset_pred = convert_to_standard_dataset(ad_conversion_dataset, \n",
    "                                            target_label_name = 'predicted_conversion',\n",
    "                                            scores_name='predicted_probability')\n",
    "\n",
    "# Use this to create the original dataset\n",
    "ad_standard_dataset_orig = ad_standard_dataset_pred.copy()\n",
    "ad_standard_dataset_orig.labels = ad_conversion_dataset[\"true_conversion\"].values.reshape(-1, 1)\n",
    "ad_standard_dataset_orig.scores = ad_conversion_dataset[\"true_conversion\"].values.reshape(-1, 1)\n",
    "\n",
    "# After converting dataset to Standard dataset your privileged class will always be 1 \n",
    "# & the others would be 0 . If the column is already binary it doesn't convert to 0 & 1.\n",
    "\n",
    "privileged_groups= [{'homeowner': 0}]\n",
    "unprivileged_groups = [{'homeowner': 1}]\n",
    "\n",
    "metric_orig = BinaryLabelDatasetMetric(ad_standard_dataset_orig, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(f\"Disparate impact for the original dataset = {metric_orig.disparate_impact():.4f}\")\n",
    "\n",
    "metric_pred = BinaryLabelDatasetMetric(ad_standard_dataset_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(f\"Disparate impact for the predicted dataset = {metric_pred.disparate_impact():.4f}\")\n",
    "\n",
    "# Split the standard dataset into train, test and validation \n",
    "# (use the same random seed to ensure instances are split in the same way)\n",
    "random_seed = 1001\n",
    "dataset_orig_train, dataset_orig_vt = ad_standard_dataset_orig.split([0.7], \n",
    "                                                shuffle=True, seed=random_seed)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], \n",
    "                                                shuffle=True, seed=random_seed+1)\n",
    "\n",
    "print(f\"Original training dataset shape: {dataset_orig_train.features.shape}\")\n",
    "print(f\"Original validation dataset shape: {dataset_orig_valid.features.shape}\")\n",
    "print(f\"Original testing dataset shape: {dataset_orig_test.features.shape}\")\n",
    "\n",
    "dataset_pred_train, dataset_pred_vt = ad_standard_dataset_pred.split([0.7], \n",
    "                                                shuffle=True, seed=random_seed)\n",
    "dataset_pred_valid, dataset_pred_test = dataset_pred_vt.split([0.5], \n",
    "                                                shuffle=True, seed=random_seed+1)\n",
    "\n",
    "print(f\"Predicted training shape: {dataset_pred_train.features.shape}\")\n",
    "print(f\"Predicted validation shape: {dataset_pred_valid.features.shape}\")\n",
    "print(f\"Predicted testing shape: {dataset_pred_test.features.shape}\")\n",
    "\n",
    "# print out some labels, names, etc. for the predicted dataset\n",
    "display(Markdown(\"#### Training Dataset shape\"))\n",
    "print(dataset_pred_train.features.shape)\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_pred_train.favorable_label, dataset_pred_train.unfavorable_label)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_pred_train.protected_attribute_names)\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_pred_train.privileged_protected_attributes, \n",
    "      dataset_pred_train.unprivileged_protected_attributes)\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_pred_train.feature_names)\n",
    "\n",
    "# Best threshold for classification only (no fairness)\n",
    "\n",
    "num_thresh = 300\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    \n",
    "    fav_inds = dataset_pred_valid.scores > class_thresh\n",
    "    dataset_pred_valid.labels[fav_inds] = dataset_pred_valid.favorable_label\n",
    "    dataset_pred_valid.labels[~fav_inds] = dataset_pred_valid.unfavorable_label\n",
    "    \n",
    "    classified_metric_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                             dataset_pred_valid, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_valid.true_positive_rate()\\\n",
    "                       +classified_metric_valid.true_negative_rate())\n",
    "\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]\n",
    "\n",
    "print(\"Best balanced accuracy (no fairness constraints) = %.4f\" % np.max(ba_arr))\n",
    "print(\"Optimal classification threshold (no fairness constraints) = %.4f\" % best_class_thresh)\n",
    "\n",
    "# Metric used (should be one of allowed_metrics)\n",
    "metric_name = \"Statistical parity difference\"\n",
    "\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "        \n",
    "#random seed for calibrated equal odds prediction\n",
    "np.random.seed(1)\n",
    "\n",
    "# Verify metric name\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "if metric_name not in allowed_metrics:\n",
    "    raise ValueError(\"Metric name should be one of allowed metrics\")\n",
    "    \n",
    "# Fit the method\n",
    "ROC = RejectOptionClassification(unprivileged_groups=unprivileged_groups,\n",
    "                                 privileged_groups=privileged_groups,\n",
    "                                            low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                            num_class_thresh=100, num_ROC_margin=50,\n",
    "                                            metric_name=metric_name,\n",
    "                                            metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "dataset_transf_pred_valid = ROC.fit_predict(dataset_orig_valid, dataset_pred_valid)\n",
    "\n",
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC.ROC_margin)\n",
    "\n",
    "metric_pred_valid_transf = BinaryLabelDatasetMetric(dataset_transf_pred_valid, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Postprocessed predicted validation dataset\"))\n",
    "print(f\"Disparate impact of unprivileged vs privileged groups = {metric_pred_valid_transf.disparate_impact():.4f}\")\n",
    "\n",
    "# Metrics function\n",
    "from collections import OrderedDict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def compute_metrics(dataset_true, dataset_pred, \n",
    "                    unprivileged_groups, privileged_groups,\n",
    "                    disp = True):\n",
    "    \"\"\" Compute the key metrics \"\"\"\n",
    "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
    "                                                 dataset_pred, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
    "    \n",
    "    if disp:\n",
    "        for k in metrics:\n",
    "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Metrics for the test set\n",
    "fav_inds = dataset_pred_test.scores > best_class_thresh\n",
    "dataset_pred_test.labels[fav_inds] = dataset_pred_test.favorable_label\n",
    "dataset_pred_test.labels[~fav_inds] = dataset_pred_test.unfavorable_label\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "\n",
    "metric_test_bef = compute_metrics(dataset_orig_test, dataset_pred_test, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "\n",
    "# Metrics for the transformed test set\n",
    "dataset_transf_pred_test = ROC.predict(dataset_pred_test)\n",
    "\n",
    "display(Markdown(\"#### Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_pred_test, \n",
    "                unprivileged_groups, privileged_groups)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
