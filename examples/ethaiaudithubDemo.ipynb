{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import time\n",
    "\n",
    "# Add a sleep statement to wait for imports to be fully loaded\n",
    "time.sleep(20)  # You can adjust the sleep duration based on your needs\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "time.sleep(20)\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "time.sleep(20)\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "time.sleep(20)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "time.sleep(20)\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_orig = GermanDataset(\n",
    "    protected_attribute_names=['age'],           # this dataset also contains protected\n",
    "                                                 # attribute for \"sex\" which we do not\n",
    "                                                 # consider in this evaluation\n",
    "    privileged_classes=[lambda x: x >= 25],      # age >=25 is considered privileged\n",
    "    features_to_drop=['personal_status', 'sex'] # ignore sex-related attributes\n",
    ")\n",
    "\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf_train = RW.fit_transform(dataset_orig_train)\n",
    "\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n",
    "\n",
    "# Additional fairness metrics\n",
    "display(Markdown(\"#### Fairness metrics on transformed training dataset\"))\n",
    "\n",
    "# Disparate Impact\n",
    "disparate_impact = metric_transf_train.disparate_impact()\n",
    "print(\"Disparate Impact (favorable label):\", disparate_impact)\n",
    "\n",
    "# Statistical Parity Difference\n",
    "statistical_parity_difference = metric_transf_train.statistical_parity_difference()\n",
    "print(\"Statistical Parity Difference (favorable label):\", statistical_parity_difference)\n",
    "\n",
    "# Create a new dataset by applying the same preprocessing steps as the transformed dataset\n",
    "dataset_orig_train_pred = RW.transform(dataset_orig_train)\n",
    "\n",
    "# Classification Metrics\n",
    "classified_metric_transf_train = ClassificationMetric(dataset_orig_train_pred, \n",
    "                                                      dataset_transf_train,\n",
    "                                                      unprivileged_groups=unprivileged_groups,\n",
    "                                                      privileged_groups=privileged_groups)\n",
    "\n",
    "# Equal Opportunity Difference\n",
    "equal_opportunity_difference = classified_metric_transf_train.equal_opportunity_difference()\n",
    "print(\"Equal Opportunity Difference:\", equal_opportunity_difference)\n",
    "\n",
    "# Equalized Odds Difference\n",
    "equalized_odds_difference = classified_metric_transf_train.equalized_odds_difference()\n",
    "print(\"Equalized Odds Difference:\", equalized_odds_difference)\n",
    "\n",
    "# Average Odds Difference\n",
    "average_odds_difference = classified_metric_transf_train.average_odds_difference()\n",
    "print(\"Average Odds Difference:\", average_odds_difference)\n",
    "\n",
    "# Theil Index\n",
    "theil_index = classified_metric_transf_train.theil_index()\n",
    "print(\"Theil Index:\", theil_index)\n",
    "\n",
    "# Predictive Parity\n",
    "predictive_parity_difference = classified_metric_transf_train.predictive_parity_difference()\n",
    "print(\"Predictive Parity Difference:\", predictive_parity_difference)\n",
    "\n",
    "# Define function to plot fairness metrics\n",
    "def plot_fairness_metrics(disparate_impact, statistical_parity_difference, equal_opportunity_difference, \n",
    "                          equalized_odds_difference, average_odds_difference, theil_index, \n",
    "                          predictive_parity_difference):\n",
    "    labels = ['Disparate Impact', 'Statistical Parity Difference', 'Equal Opportunity Difference', \n",
    "              'Equalized Odds Difference', 'Average Odds Difference', 'Theil Index', \n",
    "              'Predictive Parity Difference']\n",
    "    metrics = [disparate_impact, statistical_parity_difference, equal_opportunity_difference, \n",
    "               equalized_odds_difference, average_odds_difference, theil_index, \n",
    "               predictive_parity_difference]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(labels, metrics, color='skyblue')\n",
    "    plt.title('Fairness Metrics')\n",
    "    plt.xlabel('Value')\n",
    "    plt.xlim(0, max(metrics) * 1.2)  # Adjust xlim for better visualization\n",
    "    plt.show()\n",
    "\n",
    "# Plot fairness metrics\n",
    "plot_fairness_metrics(disparate_impact, statistical_parity_difference, equal_opportunity_difference, \n",
    "                      equalized_odds_difference, average_odds_difference, theil_index, \n",
    "                      predictive_parity_difference)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
