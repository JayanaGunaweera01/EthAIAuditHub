{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f294200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-01T09:08:15.715634Z",
     "iopub.status.busy": "2024-04-01T09:08:15.715197Z",
     "iopub.status.idle": "2024-04-01T09:10:04.815215Z",
     "shell.execute_reply": "2024-04-01T09:10:04.814527Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 09:08:36.236889: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-01 09:08:37.120837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "`load_boston` has been removed from scikit-learn since version 1.2.\n",
      "\n",
      "The Boston housing prices dataset has an ethical problem: as\n",
      "investigated in [1], the authors of this dataset engineered a\n",
      "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "positive impact on house prices [2]. Furthermore the goal of the\n",
      "research that led to the creation of this dataset was to study the\n",
      "impact of air quality but it did not give adequate demonstration of the\n",
      "validity of this assumption.\n",
      "\n",
      "The scikit-learn maintainers therefore strongly discourage the use of\n",
      "this dataset unless the purpose of the code is to study and educate\n",
      "about ethical issues in data science and machine learning.\n",
      "\n",
      "In this special case, you can fetch the dataset from the original\n",
      "source::\n",
      "\n",
      "    import pandas as pd\n",
      "    import numpy as np\n",
      "\n",
      "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "    target = raw_df.values[1::2, 2]\n",
      "\n",
      "Alternative datasets include the California housing dataset and the\n",
      "Ames housing dataset. You can load the datasets as follows::\n",
      "\n",
      "    from sklearn.datasets import fetch_california_housing\n",
      "    housing = fetch_california_housing()\n",
      "\n",
      "for the California housing dataset and::\n",
      "\n",
      "    from sklearn.datasets import fetch_openml\n",
      "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "for the Ames housing dataset.\n",
      "\n",
      "[1] M Carlisle.\n",
      "\"Racist data destruction?\"\n",
      "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
      "\n",
      "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "\"Hedonic housing prices and the demand for clean air.\"\n",
      "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
      ": LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")  \n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import time\n",
    "\n",
    "# Add a sleep statement to wait for imports to be fully loaded\n",
    "time.sleep(20) \n",
    "\n",
    "# Create a TensorFlow session\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "sess = tf.Session()\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "time.sleep(20)\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "time.sleep(20)\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "time.sleep(20)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "time.sleep(20)\n",
    "\n",
    "# Function to initialize the Reweighing algorithm\n",
    "def initialize_reweighing(unprivileged_groups, privileged_groups):\n",
    "    return Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                      privileged_groups=privileged_groups)\n",
    "\n",
    "# Function to initialize the AdversarialDebiasing algorithm\n",
    "def initialize_adversarial_debiasing(unprivileged_groups, privileged_groups, adversary_loss_weight, num_epochs, batch_size, classifier_num_hidden_units, debias, sess):\n",
    "    scope_name = \"my_scope\"\n",
    "    return AdversarialDebiasing(unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups,\n",
    "                                scope_name=scope_name,\n",
    "                                sess=sess,\n",
    "                                seed=None,\n",
    "                                adversary_loss_weight=adversary_loss_weight,\n",
    "                                num_epochs=num_epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                classifier_num_hidden_units=classifier_num_hidden_units,\n",
    "                                debias=debias)\n",
    "\n",
    "# Function to initialize the OptimPreproc algorithm\n",
    "def initialize_optim_preproc(unprivileged_groups, privileged_groups, optimizer, optim_options, verbose):\n",
    "    return OptimPreproc(optimizer=optimizer,\n",
    "                        optim_options=optim_options,\n",
    "                        unprivileged_groups=unprivileged_groups,\n",
    "                        privileged_groups=privileged_groups,\n",
    "                        verbose=verbose,\n",
    "                        seed=None)\n",
    "\n",
    "# Load dataset\n",
    "dataset_orig = GermanDataset(\n",
    "    protected_attribute_names=['age'],\n",
    "    privileged_classes=[lambda x: x >= 25],\n",
    "    features_to_drop=['personal_status', 'sex']\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "# Define privileged and unprivileged groups\n",
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "# Define metric\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                           unprivileged_groups=unprivileged_groups,\n",
    "                           privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "# Initialize ALG as None initially\n",
    "ALG = None\n",
    "\n",
    "# User-inputted algorithm\n",
    "algorithm_choice = \"Reweighing\"\n",
    "\n",
    "# Initialize algorithm based on user input \n",
    "if algorithm_choice == \"Reweighing\":\n",
    "    ALG = initialize_reweighing(unprivileged_groups, privileged_groups)\n",
    "elif algorithm_choice == \"AdversarialDebiasing\":\n",
    "    ALG = initialize_adversarial_debiasing(unprivileged_groups, privileged_groups, \n",
    "                                           adversary_loss_weight=0.1, num_epochs=50, batch_size=128, \n",
    "                                           classifier_num_hidden_units=200, debias=True, sess=sess)\n",
    "elif algorithm_choice == \"OptimPreproc\":\n",
    "    ALG = initialize_optim_preproc(unprivileged_groups, privileged_groups, \n",
    "                                   optimizer='my_optimizer', optim_options={'option1': 'value1', 'option2': 'value2'}, \n",
    "                                   verbose=False)\n",
    "\n",
    "# Fit and transform dataset\n",
    "dataset_transf_train = ALG.fit_transform(dataset_orig_train)\n",
    "\n",
    "# Compute metric on transformed dataset\n",
    "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "# Display results\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
