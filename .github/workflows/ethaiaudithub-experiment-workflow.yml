name: ğŸ‘¨â€ğŸ”¬ EthAIAuditHub Experiment Workflow

on:
  workflow_dispatch:
     inputs:
      name:
        description: 'ğŸ“— Enter a name for your notebook (ex: output_notebook.ipynb )'
        required: true
      notebook:
        description: "ğŸ“’ Select the notebook you need to run."
        type: choice
        options:
          - "ethaiaudithubTest.ipynb"
          - "ethaiaudithubExtended.ipynb"
      demoMetric1:
        description: 'ğŸ“ Select Metric1'
        default: "BinaryLabelDatasetMetric"
        type: choice
        options:
          - "DatasetMetric"
          - "BinaryLabelDatasetMetric"
          - "ClassificationMetric"
          - "SampleDistortionMetric"
          - "MDSSClassificationMetric"
      demoMetric2:
        description: 'ğŸ“ Select if you need to test with a second metric'
        default: "ClassificationMetric"
        type: choice
        options:
          - "DatasetMetric"
          - "BinaryLabelDatasetMetric"
          - "ClassificationMetric"
          - "SampleDistortionMetric"
          - "MDSSClassificationMetric"
      demoDataset:
        description: 'ğŸ“Š Select Dataset'
        default: "GermanDataset"
        type: choice
        options:
          - "AdultDataset"
          - "BankDataset"
          - "CompasDataset"
          - "GermanDataset"
          - "LawSchoolGPADataset"
          - "MEPSDataset19"
          - "MEPSDataset20"
          - "MEPSDataset21"
      demoAlgorithm:
        description: 'ğŸ’¡ Select Algorithm (preprocessing/inprocessing/postprocessing)'
        default: "Reweighing"
        type: choice
        options:
          - "Reweighing"
          - "DisparateImpactRemover"
          - "LFR"
          - "OptimPreproc"
          - "AdversarialDebiasing"
          - "ARTClassifier"
          - "GerryFairClassifier"
          - "MetaFairClassifier"
          - "PrejudiceRemover"
          - "ExponentiatedGradientReduction"
          - "GridSearchReduction"
          - "CalibratedEqOddsPostprocessing"
          - "EqOddsPostprocessing"
          - "RejectOptionClassification"
          - "DeterministicReranking"
      demoAlgoPath:
        description: 'ğŸ‘£ Enter path of the file containing Algorithm.Ex:preprocessing.optim_preproc_helpers.data_preproc_functions\'
        required: false
      dataset:
        description: 'ğŸ—ƒï¸ Enter Dataset URL if you need any, except basic datasets'
        required: false
      algorithm:
        description: 'âš™ï¸ Enter Algorithm URL if you need any, except basic algorithms'
        required: false
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # Job to build Python environment
  build-py:
    # Specify the operating system for the job
    runs-on: ubuntu-latest

    # Define strategy for job execution
    strategy:
      fail-fast: false
      # Matrix strategy allows running multiple configurations
      matrix:
        python-version: [ 3.11]  # Define Python version to use

    # Define environment variables for the job
    env:
      # URLs for UCI Machine Learning Repository and ProPublica GitHub
      UCI_DB: "https://archive.ics.uci.edu/ml/machine-learning-databases"
      PROPUBLICA_GH: "https://raw.githubusercontent.com/propublica/compas-analysis/bafff5da3f2e45eca6c2d5055faad269defd135a"
      # Access token for repository authentication
      REPO_KEY: ${{secrets.ETHAI_AUDIT_HUB_GITHUB_TOKEN}}
      # Define a username for GitHub Actions
      username: github-actions

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out the repository under $GITHUB_WORKSPACE, so the job can access it
      - name: ğŸ“¥ Check out repo 
        uses: actions/checkout@v3
    
      - name: ğŸ“¦ Set up R 
        uses: r-lib/actions/setup-r@v2
    
      - name: ğŸ Set up Python ${{ matrix.python-version }} 
        uses: actions/setup-python@v3
        with:
          python-version: ${{ matrix.python-version }}
    
      - name: ğŸ“¢ Echo Inputs 
        run: |
          echo -e "\e[1;34mName:\e[0m ${{ github.event.inputs.name }}"
          echo -e "\e[1;34mNotebook:\e[0m ${{ github.event.inputs.notebook }}"
          echo -e "\e[1;34mDemo Metric 1:\e[0m ${{ github.event.inputs.demoMetric1 }}"
          echo -e "\e[1;34mDemo Metric 2:\e[0m ${{ github.event.inputs.demoMetric2 }}"
          echo -e "\e[1;34mDemo Dataset:\e[0m ${{ github.event.inputs.demoDataset }}"
          echo -e "\e[1;34mDemo Algorithm:\e[0m ${{ github.event.inputs.demoAlgorithm }}"
          echo -e "\e[1;34mDemo Algorithm Path:\e[0m ${{ github.event.inputs.demoAlgoPath }}"
          echo -e "\e[1;34mDataset URL:\e[0m ${{ github.event.inputs.dataset }}"
          echo -e "\e[1;34mAlgorithm URL:\e[0m ${{ github.event.inputs.algorithm }}"
    
      - name: ğŸ“¦ Install dependencies 
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e '.[all]'
          pip install flake8
          pip list
          python -m rpy2.situation
    
      - name: ğŸ“Š Download basic datasets 
        run: |
          wget ${UCI_DB}/adult/adult.data -P aif360/data/raw/adult/
          # Add more wget commands for other datasets
    
      - name: ğŸ“Š Download extra datasets 
        run: |
          if [ -n "${{ inputs.dataset }}" ]; then
            wget ${{ inputs.dataset }}
          else
            echo "No dataset URL provided. Skipping download."
          fi
    
      - name: ğŸ“‚ Unzip or untar the downloaded dataset 
        if: ${{ inputs.dataset }}
        run: |
          mkdir -p temp_folder
          # Add commands to unzip or untar the dataset files
    
      - name: ğŸ“„ Copy CSV files to GitHub workspace 
        run: |
          if [ -d temp_folder ]; then
            find temp_folder -type f -name "*.csv" -exec cp -r {} ${{ github.workspace }}/examples \;
            rm -rf temp_folder
          else
            echo "Error:No CSV file found."
          fi
    
      - name: ğŸ“‹ List all the files in directory 
        run: ls -a
    
      - name: ğŸ§¹ Lint with flake8 
        run: |
          # Add commands for linting with flake8
    
      - name: ğŸ“’ Divert to Jupyter notebook directory 
        run: |
          cd ${{ github.workspace }}/examples
          ls -a
    
      - name: ğŸš€ Execute Jupyter Notebook 
        run: |
           cd ${{ github.workspace }}/examples
           pwd
           # Add commands to execute Jupyter notebook
    
      - name: ğŸ“ Commit updated notebook 
        uses: EndBug/add-and-commit@v7
        with:
          author_name: Plot update bot
          message: "Added executed notebook"
          add: "${{ github.workspace }}/automation/${{ github.event.inputs.name }}"
      
      # Add a new step to commit and push the changes
      - name: ğŸ”€ Commit and Push Changes 
        run: |
          git config --local user.name actions-user
          git config --local user.email "actions@github.com"
    
      - name: ğŸ“‚ Persist Logs 
        run: |
          mkdir -p ${{ github.workspace }}/automation/artifacts
          cp ${{ github.workspace }}/automation/${{ github.event.inputs.name }} ${{ github.workspace }}/automation/artifacts/
        if: ${{ always() }}
    
      - name: ğŸ“¤ Upload Artifacts 
        uses: actions/upload-artifact@v2
        if: always()
        with:
          name: "Audit Report ${{ github.actor }} - ${{ github.run_number }} "
          path: ${{ github.workspace }}/automation/artifacts
  build-r:
   runs-on: ubuntu-latest

   # Define strategy for job execution
   strategy:
    fail-fast: false
    # Matrix strategy allows running multiple configurations
    matrix:
      python-version: [3.11]

   steps:
    # Checkout the repository
    - name: ğŸ“¥ Check out repo 
      uses: actions/checkout@v3

    # Set up R environment
    - name: ğŸ“¦ Set up R 
      uses: r-lib/actions/setup-r@v2

    # Set up Python environment
    - name: ğŸ Set up Python ${{ matrix.python-version }} 
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}

    # Install R dependencies
    - name: ğŸ“¦ Install R dependencies 
      run: install.packages(c("reticulate", "rstudioapi", "testthat"))
      shell: Rscript {0}

    # Install Python dependencies
    - name: ğŸ“¦ Install Python dependencies 
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install '.[all]'

    # Install R package
    - name: ğŸ“¦ Install R package 
      run: R CMD INSTALL aif360/aif360-r

